# lists

https://github.com/ksopyla/awesome-nlp-polish  
https://github.com/sdadas/polish-nlp-resources - mentioned in previous list but got many different things  
http://clip.ipipan.waw.pl/LRT  
https://datasets.quantumstat.com/  
https://github.com/EthicalML/awesome-production-machine-learning  


# conferences
ICASSP  
INTERSPEECH  
LREC  
ICLR  
https://www.isca-speech.org/iscapad/iscapad.php?module=category&id=1675&back=p,264 - other events  

# scripts

https://gist.github.com/ksopyla/f05fe2f48bbc9de895368b8a7863b5c3 - Polish abbreviations  


# tools
http://nlp.actaforte.pl:8080/NLP3W/ - odmiana liczebnikÃ³w  
https://exp.lobi.nencki.gov.pl/nawl-analysis - Nencki Affective Word List (sentiment analysis)  
https://github.com/NVIDIA/Megatron-LM - nvidia BERT like training facility  


# libraries

https://github.com/facebookresearch/faiss  


# frameworks

https://github.com/allenai/allennlp  
https://github.com/pytorch/fairseq  
stanfordNLP  
flair  
facebook research  
google research  
openai  
gensim  
fasttext  
https://github.com/allenai/allennlp
https://gluon-nlp.mxnet.io/  gluon NLP

# models

https://github.com/sdadas/polish-roberta/  
https://github.com/sdadas/polish-sentence-evaluation/  

# resources
https://datasets.quantumstat.com/  
https://tatoeba.org/eng/downloads  
https://github.com/facebookresearch/ParlAI  
http://opus.nlpl.eu/  
https://commoncrawl.org/ - but oscar is preprocessed already  
https://github.com/JRMeyer/open-speech-corpora  
http://nkjp.pl/index.php?page=14&lang=0  

# papers

https://arxiv.org/pdf/1607.01759.pdf Bag of Tricks for Efficient Text Classification  
https://research.fb.com/wp-content/uploads/2020/05/An-Empirical-Study-of-Transformer-Based-Neural-Language-Model-Adaptation.pdf  


# learning/tutorials

https://www.groundai.com/  
https://nlpoverview.com/  
https://github.com/mhagiwara/100-nlp-papers  
https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/ - how to build BERT based model.  
http://d2l.ai/  
http://www.deepdata.pl/uncategorized/przygotowanie-polskiego-modelu-word2vec-z-wykorzystaniem-korpusu-opensubtitles/  
http://www.deepdata.pl/nlp-scikit-learn-klasyfikacja/przyklad-klasyfikacji-polskich-tekstow-czesc-1/  
https://distill.pub/  
https://colah.github.io/  


# benchmarks

http://clip.ipipan.waw.pl/benchmarks  
https://klejbenchmark.com/leaderboard  
https://hotpotqa.github.io/  
https://www.groundai.com/  
https://nlpoverview.com/  
https://github.com/mhagiwara/100-nlp-papers  
https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/ - how to build BERT based model.  
http://d2l.ai/  
http://www.deepdata.pl/uncategorized/przygotowanie-polskiego-modelu-word2vec-z-wykorzystaniem-korpusu-opensubtitles/  
http://www.deepdata.pl/nlp-scikit-learn-klasyfikacja/przyklad-klasyfikacji-polskich-tekstow-czesc-1/  
https://distill.pub/  
https://colah.github.io/  
https://github.com/amosjyng/ML-cheatsheet/releases  

# benchmarks

http://clip.ipipan.waw.pl/benchmarks  
https://klejbenchmark.com/leaderboard  
https://hotpotqa.github.io/  
https://gluebenchmark.com/leaderboard  


# where to look after...

https://github.com/topics  
https://paperswithcode.com  
https://www.reddit.com/r/MachineLearning/  
https://www.reddit.com/r/LanguageTechnology/  
google -> github + awesome  


# verify usefuleness

http://mist-deid.sourceforge.net/docs_2_0/html/index.html  
https://towardsdatascience.com/a-list-of-beginner-friendly-nlp-projects-using-pre-trained-models-dc4768b4bec0  
http://cl.haifa.ac.il/projects/L2/index.shtml <- interesting, but I'm not sure if for us  
https://github.com/glample/fastBPE - should we use it to tokenize ?  


# topics

## tensorflow goodies

https://github.com/tensorflow/text  


## language identificaton

fasttext
https://github.com/joshdevins/demo-es-lang-ident  
https://github.com/MartinThoma/wili-2018  
https://github.com/LauraRuis/LanguageIdentification  


## sentiment analysis

https://exp.lobi.nencki.gov.pl/nawl-analysis  
https://github.com/rafalposwiata/EDAs  
